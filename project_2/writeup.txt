In order to implement my website interface, I hand-crafted some vanilla
javascript to add in any elements after making an XMLHttpRequest (XHR) to my server
to retrieve suggestions for whatever the user has currently input.
Unfortunately, due to a restriction by browsers, there can only be up to 5 (in
google chrome) threads running at once to handle XHR's, meaning that if the user
types a word very quickly, it can take a bit of time to catch up. However, this
is not due to any problems with the searching on the backend. I made the
dropdown of suggestions into <a> tags so that you can simply tab to get to one,
and then pressing enter will complete the search bar for you.

On the backend, I took the titles from wikipedia, and combed them using a python
script in order to filter out titles that were not purely alphanumeric (except
also including spaces). Then, I uploaded that file to azure's blob storage, and
created a cloud service in azure. This cloud service will download the file from
blob storage into a temp file on the filesystem, and from there will read each
line into a hybrid Trie-List structure, with end nodes being made up of lists,
and other nodes being Tries. When queried, I will recursively call down into the
structure to get to the next letters that are of interest to me. To have the
structure build, I have a separate "build" method that I can call in order to
rebuild the trie. However, if there is some catastrophic error in which the trie
dies (server goes down and I don't notice) then if a user is to issue a query,
the backend will see that the trie doesn't currently exist, and try to rebuild
it. Not the best UX in that situation, but it is only to happen if there was
something bad happening (DDoS attack happened earlier, memory corrupted/ran out,
etc.). In order to keep the Trie alive though, I am making use of a free service
called Uptime Robot so that it will make a GET request to my server at that page
every 5 minutes. This should be able to keep my Trie in memory.
